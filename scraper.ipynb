{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sectiontally import SectionTally\n",
    "from tqdm.autonotebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SectionTally(term='Spring 2025')\n",
    "df = st.df\n",
    "subjs = df['Subj'].unique()\n",
    "courses = {}\n",
    "for subj in subjs:\n",
    "    courses[subj] = df[df['Subj'] == subj]['Crse'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [04:59<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "catalog = {}\n",
    "for subj in tqdm(courses):\n",
    "    for crse in courses[subj]:\n",
    "        response = requests.post(url='https://banner9.rowan.edu/ords/ssb/bwckctlg.p_disp_course_detail',\n",
    "            data= {'cat_term_in': st.term,\n",
    "                    'subj_code_in': subj,\n",
    "                    'crse_numb_in': crse})\n",
    "\n",
    "        assert (response.status_code == 200), f\"error: {response.status_code}, unable to find course\"\n",
    "        \n",
    "        catalog[f'{subj} {crse}'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class CourseExtractor():\n",
    "    def __init__(self, soup: BeautifulSoup) -> None:\n",
    "        self.soup = soup\n",
    "        \n",
    "    def extract_preqs(self) -> str:\n",
    "            \"\"\"\n",
    "                extracts prerequisites from Rowan's detailed course information website\n",
    "                \n",
    "                Args:\n",
    "                    soup: BeautifulSoup of Rowan course information HTML\n",
    "                Returns:\n",
    "                    preqs: Preq parser\n",
    "            \"\"\"\n",
    "            preq_head = self.soup.find('span', 'fieldlabeltext', string=re.compile('Prerequisites', re.IGNORECASE))\n",
    "            if preq_head == None:\n",
    "                return None\n",
    "\n",
    "            assert (preq_head.next_siblings != None), \"nothing found after 'Prerequisites: '\"\n",
    "                \n",
    "            res = []\n",
    "            prev_tag = ''\n",
    "            for sibling in preq_head.next_siblings:\n",
    "                if sibling == '\\n':\n",
    "                    continue\n",
    "\n",
    "                if (sibling.name == 'br') and (prev_tag == 'br'):\n",
    "                    break\n",
    "\n",
    "                prev_tag = sibling.name\n",
    "\n",
    "                s = sibling.string\n",
    "                if s != None:\n",
    "                    res.append(s)\n",
    "\n",
    "            return ''.join(res)\n",
    "            # try:\n",
    "            #     return PreqParser(''.join(res))\n",
    "            # except:\n",
    "            #     return ''.join(res)\n",
    "\n",
    "    def extract_desc(self) -> str:\n",
    "        _found = self.soup.find('td', 'ntdefault')\n",
    "        if not _found:\n",
    "            return None\n",
    "        _found = _found.findNext(string=True)\n",
    "        if not _found or _found == '\\n':\n",
    "            return None\n",
    "        return _found\n",
    "    def extract_title(self) -> str:\n",
    "        _found = self.soup.find('td', 'nttitle')\n",
    "        if not _found:\n",
    "            return None\n",
    "        return _found.string\n",
    "\n",
    "    def extract_credits(self) -> str:\n",
    "        # ensures it is credits\n",
    "        _match = re.search(r'(\\d{1}\\.\\d{,4}) (Credit)', self.soup.text)\n",
    "        if _match:\n",
    "            return _match.group(1)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2089/2089 [00:09<00:00, 225.42it/s]\n"
     ]
    }
   ],
   "source": [
    "catalog_dict = []\n",
    "\n",
    "for elm in tqdm(catalog):\n",
    "    soup = BeautifulSoup(catalog[elm], features=\"html.parser\")\n",
    "    course = CourseExtractor(soup)\n",
    "    subj, crse = elm.split()\n",
    "    catalog_dict.append({\n",
    "        \"subj\": subj,\n",
    "        \"crse\": crse,\n",
    "        \"title\": course.extract_title(),\n",
    "        \"desc\": course.extract_desc(),\n",
    "        \"preqs\": course.extract_preqs(),\n",
    "        \"creds\": course.extract_credits(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('catalog.json', 'w') as f:\n",
    "    json.dump(catalog_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 ('betterSectionTally')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21bcc8daa5091b1ee170940f0cfd4cf620e1862ae2e6996a2a5bc04203bad3e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
